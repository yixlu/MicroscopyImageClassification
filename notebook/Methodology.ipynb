{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# switch working directory to working directory of main repository \n",
    "os.chdir(\"./..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes import *\n",
    "\n",
    "reorganize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid), (X_test, y_test) = load_data();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example images\n",
    "example_idx = {}\n",
    "labels = np.unique(y_train)\n",
    "for i in labels:\n",
    "    example_idx[i] = np.where(y_train==i)[0][0]  # tinker with the last index value to experiment with different images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot example images\n",
    "def plot_images(data, idx, channels):\n",
    "    mapping = {0: \"cell periphery\", 1: \"cytoplasm\", 2: \"endosome\", 3: \"er\", 4: \"golgi\",\n",
    "               5: \"mitochondrion\", 6: \"nuclear periphery\", 7: \"nucleolus\", 8: \"nucleus\",\n",
    "               9: \"peroxisome\", 10: \"spindle pole\", 11: \"vacuole\"}\n",
    "    fig, ax = plt.subplots(2,6, figsize=(12,5))\n",
    "    if channels == 3:\n",
    "        ax[0,0].imshow(cv2.cvtColor(data[idx[0]],cv2.COLOR_BGR2RGB))\n",
    "        ax[0,0].set_title(mapping[0])\n",
    "        ax[0,1].imshow(cv2.cvtColor(data[idx[1]],cv2.COLOR_BGR2RGB))\n",
    "        ax[0,1].set_title(mapping[1])\n",
    "        ax[0,2].imshow(cv2.cvtColor(data[idx[2]],cv2.COLOR_BGR2RGB))\n",
    "        ax[0,2].set_title(mapping[2])\n",
    "        ax[0,3].imshow(cv2.cvtColor(data[idx[3]],cv2.COLOR_BGR2RGB))\n",
    "        ax[0,3].set_title(mapping[3])\n",
    "        ax[0,4].imshow(cv2.cvtColor(data[idx[4]],cv2.COLOR_BGR2RGB))\n",
    "        ax[0,4].set_title(mapping[4])\n",
    "        ax[0,5].imshow(cv2.cvtColor(data[idx[5]],cv2.COLOR_BGR2RGB))\n",
    "        ax[0,5].set_title(mapping[5])\n",
    "        ax[1,0].imshow(cv2.cvtColor(data[idx[6]],cv2.COLOR_BGR2RGB))\n",
    "        ax[1,0].set_title(mapping[6])\n",
    "        ax[1,1].imshow(cv2.cvtColor(data[idx[7]],cv2.COLOR_BGR2RGB))\n",
    "        ax[1,1].set_title(mapping[7])\n",
    "        ax[1,2].imshow(cv2.cvtColor(data[idx[8]],cv2.COLOR_BGR2RGB))\n",
    "        ax[1,2].set_title(mapping[8])\n",
    "        ax[1,3].imshow(cv2.cvtColor(data[idx[9]],cv2.COLOR_BGR2RGB))\n",
    "        ax[1,3].set_title(mapping[9])\n",
    "        ax[1,4].imshow(cv2.cvtColor(data[idx[10]],cv2.COLOR_BGR2RGB))\n",
    "        ax[1,4].set_title(mapping[10])\n",
    "        ax[1,5].imshow(cv2.cvtColor(data[idx[11]],cv2.COLOR_BGR2RGB))\n",
    "        ax[1,5].set_title(mapping[11])\n",
    "    elif channels == 1:\n",
    "        ax[0,0].imshow(data[idx[0]], cmap=\"gray\")\n",
    "        ax[0,0].set_title(mapping[0])\n",
    "        ax[0,1].imshow(data[idx[1]], cmap=\"gray\")\n",
    "        ax[0,1].set_title(mapping[1])\n",
    "        ax[0,2].imshow(data[idx[2]], cmap=\"gray\")\n",
    "        ax[0,2].set_title(mapping[2])\n",
    "        ax[0,3].imshow(data[idx[3]], cmap=\"gray\")\n",
    "        ax[0,3].set_title(mapping[3])\n",
    "        ax[0,4].imshow(data[idx[4]], cmap=\"gray\")\n",
    "        ax[0,4].set_title(mapping[4])\n",
    "        ax[0,5].imshow(data[idx[5]], cmap=\"gray\")\n",
    "        ax[0,5].set_title(mapping[5])\n",
    "        ax[1,0].imshow(data[idx[6]], cmap=\"gray\")\n",
    "        ax[1,0].set_title(mapping[6])\n",
    "        ax[1,1].imshow(data[idx[7]], cmap=\"gray\")\n",
    "        ax[1,1].set_title(mapping[7])\n",
    "        ax[1,2].imshow(data[idx[8]], cmap=\"gray\")\n",
    "        ax[1,2].set_title(mapping[8])\n",
    "        ax[1,3].imshow(data[idx[9]], cmap=\"gray\")\n",
    "        ax[1,3].set_title(mapping[9])\n",
    "        ax[1,4].imshow(data[idx[10]], cmap=\"gray\")\n",
    "        ax[1,4].set_title(mapping[10])\n",
    "        ax[1,5].imshow(data[idx[11]], cmap=\"gray\")\n",
    "        ax[1,5].set_title(mapping[11])\n",
    "    else:\n",
    "        print(\"Number of channels should be either 1 or 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how the original data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(X_train, example_idx, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image preprocessing step\n",
    "image_processor = image_preprocessing()\n",
    "\n",
    "# preprocess train data\n",
    "_ = image_processor.split_channels(X_train)\n",
    "_,_ = image_processor.ROI()\n",
    "Xn_train = image_processor.image_normalize(option=\"ROI\")\n",
    "\n",
    "# preprocess valid data\n",
    "_ = image_processor.split_channels(X_valid)\n",
    "_,_ = image_processor.ROI()\n",
    "Xn_valid = image_processor.image_normalize(option=\"ROI\")\n",
    "\n",
    "# preprocess train data\n",
    "_ = image_processor.split_channels(X_test)\n",
    "_,_ = image_processor.ROI()\n",
    "Xn_test = image_processor.image_normalize(option=\"ROI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how the normalized data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(Xn_train, example_idx, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary mask on Red Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop ROI on Green Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift-Invariant Feature Transform (SIFT) for Bag of Feature (BoF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_ = SIFT_FeatureExtractor()\n",
    "Xsift_train = sift_.fit_transform(Xn_train)\n",
    "Xsift_valid = sift_.transform(Xn_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(Xsift_train, example_idx, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Discriminant Basis (LDB) using Wavelets Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Discriminant Basis is a feature extraction technique developed by N. Saito and R. Coifman in 1995. This algorithm follows the following basic steps:\n",
    "\n",
    "1. Decompose a set of multi-class signals using wavelet packet decomposition. A wavelet packet decomposition decomposes a signal into multiple nodes which resembles a binary tree.\n",
    "2. Based on the decomposed wavelet coefficients, build an energy map based on time-frequency or probability density.\n",
    "3. Using the energy map, compute the discriminant measure and select a basis tree that best discriminates the different classes of signals.\n",
    "4. Based on the selected basis tree, extract the corresponding wavelet coefficients for each signal.\n",
    "5. Compute the discriminant power of each coefficient index. Select the top k set of coefficients to be used as features to be passed onto a classifier such as Linear Discriminant Analysis (LDA) and Classification and Regression Trees (CART).\n",
    "\n",
    "A more in-depth tutorial can be found in the Pluto notebook [here](https://github.com/ShozenD/LDBExperiments). For more information on LDB, please refer to the original paper \"Local Discriminant Basis and their Applications\" by Saito and Coifman [here](https://www.math.ucdavis.edu/~saito/publications/saito_ldb_jmiv.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from julia import Main\n",
    "\n",
    "Main.using(\"Wavelets\")\n",
    "Main.using(\"WaveletsExt\")\n",
    "\n",
    "ldb_ = LDB_FeatureExtractor(wt=Main.wavelet(Main.WT.coif4), max_dec)\n",
    "Xldb_train = ldb_.fit_transform(Xn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the best basis for the purpose of discriminating the different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main.plot_tfbdry(ldb_.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the discriminant power plot, and use the elbow rule to determine the number of features to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,64**2+1), ldb_.DP[ldb_.order])\n",
    "plt.title(\"Sorted discriminant power\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided that 100 is a fair amount of features to be extracted. So here we go..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xldb_train = ldb_.change_nfeatures(Xldb_train, 100)\n",
    "Xldb_valid = ldb_.transform(Xn_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationary Wavelet Transform (SWT) Based Feature Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This method is referenced from Qayyum et al.'s \"Facial Expression Recognition Using Stationary Wavelet Transform Features\".\n",
    "\n",
    "Another method of feature extraction is using stationary wavelet transforms (SWT). Unlike its wavelet transform counterpart, SWT does not perform downsampling, ie. the decomposed images have the exact same shape as the original signal. Therefore, the SWT is considered as a redundant transform. \n",
    "\n",
    "Since our images are decomposed into Approximation coefficients and Horizontal, Vertical and Diagonal coefficients, the total number of coefficients of the decomposed images is 4 times the number of the original image. The number of coefficients increases by a multiple of 4 if we decide to further decompose our image into more levels. For the sake of speed and efficiency, we will not pursue any decomposition beyond the first level.\n",
    "\n",
    "**SWT for Image Classification**\n",
    "\n",
    "For the purpose of image classification, incorporating SWT into our model means that we follow the steps below:\n",
    "\n",
    "1. **1 level of SWT decomposition of each image.** As mentioned previously, we will only compute one level of decomposition for each image. This will lead to us obtaining the approximate (`cA`), horizontal detail (`cH`), vertical detail (`cV`), and diagonal detail (`cD`) coefficients.\n",
    "2. **Compute the Discrete Cosine Transform (DCT) on each set of coefficients.** To reduce the size of feature coefficients, $8 \\times 8$ block DCT is applied to the `cH`, `cV`, and `cD` coefficients only. Based on Qayyum et al's paper, the DCT applied to each block is calculated as\n",
    "$$\n",
    "X(u,v) = \\frac{C(u) C(v)}{4} \\sum_{m=0}{7} \\sum_{n=0}{7} x[m,n] \\cos(\\frac{(2m+1)u\\pi}{16}) \\cos(\\frac{(2n+1)v\\pi}{16})\n",
    "$$\n",
    "where\n",
    "$$\n",
    "C(u) = \\begin{cases} \\frac{1}{\\sqrt{2}}, & u=0 \\\\ 1, & 1\\leq u \\leq 7 \\end{cases}, C(v) = \\begin{cases} \\frac{1}{\\sqrt{2}}, & v=0 \\\\ 1, & 1\\leq v \\leq 7 \\end{cases}\n",
    "$$\n",
    "This can be done using the `scipy.fftpack.dct` function and setting `type=2` and `norm=\"ortho\"`.\n",
    "3. **Reshape the results from step 2 into 1D vectors.**\n",
    "4. **Fit the result from step 4 into a classifier.**\n",
    "\n",
    "For the prediction step, we have the following pipeline:\n",
    "\n",
    "1. **1 level of SWT decomposition of each image.**\n",
    "2. **Compute the Discrete Cosine Transform (DCT) on each set of coefficients.**\n",
    "3. **Reshape the results from step 2 into 1D vectors.**\n",
    "4. **Fit the result from step 4 into a classifier.**\n",
    "\n",
    "*Note: Interestingly, Qayyum et al did not use the approximation coefficients in the image classification process. Whether that can have some drastic effect remains to be seen. Maybe at the end of the day we apply SIFT on the approximation coefficients?*\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "* SWT is shift invariant, which can be important when it comes to feature extraction in cell images.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "* Due to its redundant nature, the SWT is significantly less efficient that the DWT, and this may pose a problem with the large number of images that we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stationary Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "# play around with the images and wavelets to observe the effect of SWT\n",
    "# also try out with contrast-adjusted images\n",
    "im = Xn_train[example_idx[0]]\n",
    "wt = \"Haar\"\n",
    "\n",
    "cA, (cH, cV, cD) = pywt.swt2(im, wt, 1, 0, trim_approx=True)\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(6,6))\n",
    "ax[0,0].imshow(cA, cmap=\"gray\")\n",
    "ax[0,0].set_title(\"Approx coef. (LL)\")\n",
    "ax[0,1].imshow(cH, cmap=\"gray\")\n",
    "ax[0,1].set_title(\"Detail coef. (LH)\")\n",
    "ax[1,0].imshow(cV, cmap=\"gray\")\n",
    "ax[1,0].set_title(\"Detail coef. (HL)\")\n",
    "ax[1,1].imshow(cD, cmap=\"gray\")\n",
    "ax[1,1].set_title(\"Detail coef. (HH)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete Cosine Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import dct\n",
    "\n",
    "result = []\n",
    "for mat in [cH, cV, cD]:\n",
    "    dmat = dct(dct(mat, 2, axis=0, norm=\"ortho\"), 2, axis=1, norm=\"ortho\")\n",
    "    result += [dmat[::8, ::8]]\n",
    "\n",
    "# plotting heatmap of results from DCT\n",
    "fig, ax = plt.subplots(1,3)\n",
    "ax[0].imshow(result[0])\n",
    "ax[1].imshow(result[1])\n",
    "ax[2].imshow(result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swt_ = SWT_FeatureExtractor(wt=\"coif4\")\n",
    "Xswt_train = swt_.fit_transform(Xn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haralick texture features based on GLCM (gray level co-occurrence matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeded-up Robust Features (SURF) for Bag of Feature (BoF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelets Scattering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDB Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWT Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haralick Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SURF Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelets Scattering Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cells)",
   "language": "python",
   "name": "cells"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "248.722px",
    "left": "1375.45px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
